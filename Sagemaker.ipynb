{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install -U sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sagemaker\n",
    "from sagemaker.pytorch import PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(\n",
    "    entry_point=\"model.py\",\n",
    "    source_dir=\"model\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.10.0\",\n",
    "    instance_count=2,\n",
    "    use_spot_instances=True,\n",
    "    input_mode=\"FastFile\",  # Amazon SageMaker streams data from S3 on demand instead of downloading the entire dataset before training begins.\n",
    "    instance_type=\"ml.g4dn.12xlarge\",\n",
    "    max_run=60\n",
    "    * 60\n",
    "    * 60,  # Timeout in seconds for training. After this amount of time Amazon SageMaker terminates the job regardless of its current status.\n",
    "    max_wait=60\n",
    "    * 2\n",
    "    * 60\n",
    "    * 60,  # Timeout in seconds waiting for spot training job. After this amount of time Amazon SageMaker will stop waiting for managed spot training job to complete.\n",
    "    volume_size=900,  # Size in GB of the EBS volume to use for storing input data during training (default: 30).\n",
    "    hyperparameters={\n",
    "        \"epochs\": 1,\n",
    "        # https://pytorch.org/docs/stable/distributed.html\n",
    "        # TODO: nccl\n",
    "        \"backend\": \"gloo\",  # Use the Gloo backend for distributed CPU training. Use the NCCL backend for distributed GPU training. If you encounter any problem with NCCL, use Gloo as the fallback option.\n",
    "        \"batch-size\": 512,\n",
    "    },  # Hyperparameters to initialize this estimator with.\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = \"s3://sagemaker-eu-west-1-oasprocessed/tokenized_data/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit({\"training\": inputs})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
